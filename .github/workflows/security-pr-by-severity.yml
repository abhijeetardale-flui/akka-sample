name: Security Fix Pull Requests by Severity

on:
  workflow_dispatch:
  schedule:
    - cron: '0 3 * * 1'  # Every Monday at 03:00 UTC

permissions:
  contents: write
  pull-requests: write
  security-events: read
  actions: read

jobs:
  run-scan:
    name: Run Security Scans (SAST + SCA)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create scan directory
        run: |
          mkdir -p security-scan-data

      - name: Trivy filesystem scan (all severities)
        uses: aquasecurity/trivy-action@master
        continue-on-error: true
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'json'
          output: 'security-scan-data/trivy-results.json'
          severity: 'CRITICAL,HIGH,MEDIUM,LOW'
          scanners: 'vuln'

      - name: Semgrep SAST scan (auto rules)
        continue-on-error: true
        run: |
          echo "ðŸ” Running Semgrep auto rules..."
          docker run --rm -v "${PWD}:/src" returntocorp/semgrep:latest \
            semgrep scan --config auto \
            --json --output /src/security-scan-data/semgrep-results.json \
            /src || true
          echo "âœ… Semgrep completed"

      - name: Upload scan artifacts
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-data
          path: security-scan-data/
          retention-days: 7

  create-pr-by-severity:
    name: Create security PR for ${{ matrix.severity }} issues
    needs: run-scan
    runs-on: ubuntu-latest
    strategy:
      matrix:
        severity: [CRITICAL, HIGH, MEDIUM]
    env:
      TARGET_SEVERITY: ${{ matrix.severity }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Prepare workspace
        run: |
          mkdir -p pr-fixes
          mkdir -p security-reports/auto

      - name: Download scan data
        uses: actions/download-artifact@v4
        with:
          name: security-scan-data
          path: security-scan-data

      - name: Parse scan results for severity
        id: parse
        run: |
          cat > pr-fixes/parse_by_severity.py <<'PYTHON'
import json
import os
from datetime import datetime

target_severity = os.environ.get('TARGET_SEVERITY', 'CRITICAL')
scan_dir = 'security-scan-data'
trivy_path = os.path.join(scan_dir, 'trivy-results.json')
semgrep_path = os.path.join(scan_dir, 'semgrep-results.json')

def load_json(path):
    try:
        with open(path, 'r') as handle:
            return json.load(handle)
    except FileNotFoundError:
        print(f"âš ï¸ Missing file: {path}")
    except json.JSONDecodeError as exc:
        print(f"âš ï¸ Could not decode {path}: {exc}")
    return {}

trivy_data = load_json(trivy_path)
semgrep_data = load_json(semgrep_path)

issues = []
fixes = []
sca_count = 0
sast_count = 0

# --- Process Trivy SCA results ---
if isinstance(trivy_data, dict) and 'Results' in trivy_data:
    for result in trivy_data.get('Results', []):
        for vuln in result.get('Vulnerabilities', []):
            severity = vuln.get('Severity', 'UNKNOWN')
            if severity != target_severity:
                continue
            sca_count += 1
            entry = {
                'source': 'Trivy',
                'type': 'SCA',
                'severity': severity,
                'cve': vuln.get('VulnerabilityID', 'N/A'),
                'package': vuln.get('PkgName', 'Unknown'),
                'current_version': vuln.get('InstalledVersion', 'Unknown'),
                'fixed_version': vuln.get('FixedVersion', ''),
                'title': vuln.get('Title', 'No title'),
                'description': (vuln.get('Description') or 'No description')[:400],
                'cvss': vuln.get('CVSS', {}).get('nvd', {}).get('V3Score'),
                'references': vuln.get('References', []),
            }
            issues.append(entry)

            fixed_version = vuln.get('FixedVersion') or ''
            if fixed_version and fixed_version.lower() not in ('not available', 'none'):
                fixes.append({
                    'package': entry['package'],
                    'from_version': entry['current_version'],
                    'to_version': fixed_version,
                    'cve': entry['cve'],
                    'severity': severity,
                })

# --- Process Semgrep SAST results ---
severity_map = {
    'ERROR': 'HIGH',
    'WARNING': 'MEDIUM',
    'INFO': 'LOW',
}

if isinstance(semgrep_data, dict) and 'results' in semgrep_data:
    for finding in semgrep_data.get('results', []):
        raw_severity = finding.get('extra', {}).get('severity', 'INFO')
        mapped_severity = severity_map.get(raw_severity, 'LOW')
        if mapped_severity != target_severity:
            continue
        sast_count += 1
        entry = {
            'source': 'Semgrep',
            'type': 'SAST',
            'severity': mapped_severity,
            'cve': finding.get('check_id', 'N/A'),
            'file': finding.get('path', 'Unknown'),
            'line': finding.get('start', {}).get('line'),
            'title': finding.get('extra', {}).get('message', 'Security issue detected')[:160],
            'description': finding.get('extra', {}).get('metadata', {}).get('description', 'No description')[:400],
            'references': finding.get('extra', {}).get('metadata', {}).get('references', []),
        }
        issues.append(entry)

issues.sort(key=lambda item: item.get('cve', ''))

os.makedirs('pr-fixes', exist_ok=True)
with open('pr-fixes/issues.json', 'w') as handle:
    json.dump(issues, handle, indent=2)

with open('pr-fixes/fixes.json', 'w') as handle:
    json.dump(fixes, handle, indent=2)

summary_lines = [
    f"# Security Findings â€“ {target_severity}",
    f"Generated on {datetime.utcnow().isoformat()} UTC",
    "",
    f"- Total issues: {len(issues)}",
    f"- SCA issues: {sca_count}",
    f"- SAST issues: {sast_count}",
    f"- Auto-fixable dependencies: {len(fixes)}",
    "",
]

if issues:
    summary_lines.append("## Detailed Findings")
    for idx, item in enumerate(issues, start=1):
        summary_lines.append(f"{idx}. **{item.get('cve', 'N/A')}** â€“ {item.get('title')}" )
        if item.get('type') == 'SCA':
            summary_lines.append(f"   - Package: `{item.get('package')}`")
            summary_lines.append(f"   - Version: `{item.get('current_version')}` â†’ `{item.get('fixed_version') or 'Manual review'}`")
        else:
            summary_lines.append(f"   - Location: `{item.get('file')}:{item.get('line')}`")
        summary_lines.append(f"   - Source: {item.get('source')} ({item.get('type')})")
        summary_lines.append("")
else:
    summary_lines.append("No security issues detected for this severity.")

summary_path = os.path.join('security-reports', 'auto', f"{target_severity.lower()}-security-summary.md")
with open(summary_path, 'w') as handle:
    handle.write("\n".join(summary_lines) + "\n")

output_path = os.environ.get('GITHUB_OUTPUT')
if output_path:
    with open(output_path, 'a') as handle:
        handle.write(f"issue_count={len(issues)}\n")
        handle.write(f"sca_count={sca_count}\n")
        handle.write(f"sast_count={sast_count}\n")
        handle.write(f"fixable_count={len(fixes)}\n")
        handle.write(f"has_issues={'true' if issues else 'false'}\n")
PYTHON

          python3 pr-fixes/parse_by_severity.py

      - name: Apply dependency fixes (SCA)
        if: steps.parse.outputs.fixable_count != '0'
        run: |
          cat > pr-fixes/apply_fixes.py <<'PYTHON'
import json
import subprocess
import re

with open('pr-fixes/fixes.json', 'r') as handle:
    fixes = json.load(handle)

if not fixes:
    print("â„¹ï¸ No dependency fixes to apply")
    raise SystemExit(0)

def update_file(path, old, new):
    with open(path, 'r') as fh:
        content = fh.read()
    updated = content.replace(old, new)
    if updated != content:
        with open(path, 'w') as fh:
            fh.write(updated)
        print(f"âœ… Updated {path}")
        return True
    return False

pom_files = subprocess.run(['find', '.', '-name', 'pom.xml', '-type', 'f'], capture_output=True, text=True).stdout.strip().split('\n')
sbt_files = subprocess.run(['find', '.', '-name', 'build.sbt', '-type', 'f'], capture_output=True, text=True).stdout.strip().split('\n')

changes = 0

for fix in fixes:
    pkg = fix['package']
    from_ver = fix['from_version']
    to_ver = fix['to_version']
    print(f"ðŸ”§ Updating {pkg}: {from_ver} â†’ {to_ver}")

    group = pkg.split(':')[0] if ':' in pkg else pkg
    artifact = pkg.split(':')[1] if ':' in pkg else pkg

    # Maven updates
    for pom in filter(None, pom_files):
        try:
            with open(pom, 'r') as fh:
                content = fh.read()
            original = content

            # Property style <group.version>value</group.version>
            content = content.replace(f"<{pkg}.version>{from_ver}</{pkg}.version>", f"<{pkg}.version>{to_ver}</{pkg}.version>")

            # Direct dependency version
            pattern = re.compile(rf"<groupId>{re.escape(group)}</groupId>\s*<artifactId>{re.escape(artifact)}</artifactId>\s*<version>{re.escape(from_ver)}</version>")
            content = pattern.sub(lambda _: f"<groupId>{group}</groupId><artifactId>{artifact}</artifactId><version>{to_ver}</version>", content)

            content = content.replace(f"<version>{from_ver}</version>", f"<version>{to_ver}</version>")

            if content != original:
                with open(pom, 'w') as fh:
                    fh.write(content)
                print(f"   âœ… Updated {pom}")
                changes += 1
        except Exception as exc:
            print(f"   âš ï¸ Could not update {pom}: {exc}")

    # SBT updates
    for sbt in filter(None, sbt_files):
        try:
            with open(sbt, 'r') as fh:
                content = fh.read()
            original = content

            content = re.sub(
                rf'("{re.escape(group)}"\s*%+\s*"{re.escape(artifact)}"\s*%\s*")({re.escape(from_ver)})(")',
                rf'\1{to_ver}\3',
                content
            )

            content = content.replace(f'"{from_ver}"', f'"{to_ver}"') if pkg in content else content

            if content != original:
                with open(sbt, 'w') as fh:
                    fh.write(content)
                print(f"   âœ… Updated {sbt}")
                changes += 1
        except Exception as exc:
            print(f"   âš ï¸ Could not update {sbt}: {exc}")

print(f"Total updated files: {changes}")
PYTHON

          python3 pr-fixes/apply_fixes.py

      - name: Generate PR body
        id: pr_body
        run: |
          cat > pr-fixes/generate_pr_body.py <<'PYTHON'
import json
import os

severity = os.environ.get('TARGET_SEVERITY', 'CRITICAL')

with open('pr-fixes/issues.json', 'r') as handle:
    issues = json.load(handle)

with open('pr-fixes/fixes.json', 'r') as handle:
    fixes = json.load(handle)

sca_issues = [item for item in issues if item.get('type') == 'SCA']
sast_issues = [item for item in issues if item.get('type') == 'SAST']

body = []
body.append(f"# ðŸ”’ Automated Security Fixes â€“ {severity} Severity")
body.append("")
body.append(f"This PR addresses **{len(issues)} {severity} severity security findings** detected by the comprehensive security scan.")
body.append("")

body.append("## ðŸ“Š Summary")
body.append("")
body.append("| Metric | Count |")
body.append("|--------|-------|")
body.append(f"| Total Findings | {len(issues)} |")
body.append(f"| SCA (Dependencies) | {len(sca_issues)} |")
body.append(f"| SAST (Code) | {len(sast_issues)} |")
body.append(f"| Auto-fixable dependencies | {len(fixes)} |")
body.append("")

if sca_issues:
    body.append("## ðŸ“¦ Dependency Vulnerabilities")
    for item in sca_issues:
        body.append(f"### {item['cve']} â€“ {item['title']}")
        body.append(f"- Package: `{item['package']}`")
        body.append(f"- Current version: `{item['current_version']}`")
        body.append(f"- Fixed version: `{item['fixed_version'] or 'Manual review required'}`")
        body.append(f"- Description: {item['description']}")
        body.append("")

if sast_issues:
    body.append("## ðŸ” Code Findings (Manual review required)")
    for item in sast_issues:
        body.append(f"### {item['cve']} â€“ {item['title']}")
        body.append(f"- Location: `{item['file']}:{item['line']}`")
        body.append(f"- Description: {item['description']}")
        body.append("")

if fixes:
    body.append("## âœ… Dependency Updates Applied")
    for fix in fixes:
        body.append(f"- `{fix['package']}`: `{fix['from_version']}` â†’ `{fix['to_version']}` ({fix['cve']})")
    body.append("")
else:
    body.append("## âš ï¸ Manual Action Required")
    body.append("No automatic dependency updates were available. Please review the findings above and apply manual code changes where necessary.")
    body.append("")

body.append("## ðŸ§ª Testing Checklist")
body.append("- [ ] Build succeeds")
body.append("- [ ] Unit tests pass")
body.append("- [ ] Integration tests pass")
body.append("- [ ] Security regression review complete")
body.append("")

body.append("---")
body.append("*Generated automatically by the Security Fix Pull Requests by Severity workflow.*")

with open('pr-fixes/pr-body.md', 'w') as handle:
    handle.write("\n".join(body) + "\n")
PYTHON

          python3 pr-fixes/generate_pr_body.py

      - name: Check for repository changes
        id: diff
        run: |
          if git diff --quiet; then
            echo "changes=false" >> "$GITHUB_OUTPUT"
            echo "â„¹ï¸ No changes detected â€“ skipping PR creation"
          else
            echo "changes=true" >> "$GITHUB_OUTPUT"
            echo "âœ… Repository changes detected"
            git status --short

      - name: Create pull request
        id: create_pr
        if: steps.parse.outputs.has_issues == 'true' && steps.diff.outputs.changes == 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: |
            ðŸ”’ Security fixes â€“ ${{ matrix.severity }} severity
          title: "ðŸ”’ Security: ${{ matrix.severity }} severity fixes"
          body-path: pr-fixes/pr-body.md
          branch: security/auto-fix-${{ lower(matrix.severity) }}
          delete-branch: true
          labels: |
            security
            automated-pr
            ${{ lower(matrix.severity) }}
          assignees: abhijeetardale-flui
          reviewers: abhijeetardale-flui

      - name: Publish job summary
        if: always()
        run: |
          echo "## Security Severity Summary â€“ ${{ matrix.severity }}" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "- Has issues: ${{ steps.parse.outputs.has_issues }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Total issues: ${{ steps.parse.outputs.issue_count }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- SCA issues: ${{ steps.parse.outputs.sca_count }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- SAST issues: ${{ steps.parse.outputs.sast_count }}" >> "$GITHUB_STEP_SUMMARY"
          echo "- Auto-fixable: ${{ steps.parse.outputs.fixable_count }}" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          if [ "${{ steps.parse.outputs.has_issues }}" == "true" ]; then
            echo "- Summary file: security-reports/auto/${{ lower(matrix.severity) }}-security-summary.md" >> "$GITHUB_STEP_SUMMARY"
            if [ "${{ steps.diff.outputs.changes }}" == "true" ]; then
              if [ -n "${{ steps.create_pr.outputs.pull-request-url }}" ]; then
                echo "- Pull request: ${{ steps.create_pr.outputs.pull-request-url }}" >> "$GITHUB_STEP_SUMMARY"
              fi
            else
              echo "- No repository changes detected for this severity." >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            echo "- No issues detected for this severity." >> "$GITHUB_STEP_SUMMARY"
          fi
